## Интерактивная система мониторинга и анализа трендов

Этот проект реализует многошаговый конвейер для мониторинга и анализа трендов на основе экспорта истории чата из папки `dataset/`. Система включает:

- Ненадзорное (unsupervised) выделение тем и кластеризацию, с LLM‑разметкой названий тем.
- Интерактивный интерфейс Streamlit для                         исследования данных, подсказок по интентам и zero‑shot фильтрации.
- Генерацию аналитических отчётов на основе выбранных интентов/тем с возможностью регенерации и чата по отчёту.

### Быстрый старт

1. Рекомендуется Python 3.10+. Создайте виртуальное окружение и установите зависимости:

```bash
python -m venv .venv
.venv\Scripts\python -m pip install --upgrade pip
.venv\Scripts\python -m pip install -r requirements.txt
```

2. Настройте переменные окружения

```bash
#Добавьте приватные ключи
# Откройте .env и задайте FOLDER_ID, SERVICE_ACCOUNT_ID, KEY_ID, PRIVATE_KEY, API_KEY_EMBEDDER
```

3. Запустите приложение через Fast API:

```bash
.venv\Scripts\python -m uvicorn api_server:app --reload --port 8000
```
4. Установка зависимостей фронтенда в отдельном окне

```bash
npm install
```

5. В отдельном окне терминала зайдите в директорию с фронтендом и запустите его
   
```bash
npm run dev
```

6. Перейдите в браузере по адресу проекта

```bash
http://localhost:5173/
#Адрес указан в окне npm run dev
```

Далее можете выбрать промежутки времени, в которые вам интересны новости. Осталось немного подождать и готово(рекомендуется выбирать промежуток не более 2 месяцев)!
Приложение прочитает `dataset/result.json`, посчитает эмбеддинги и кластеры, выполнит разметку тем моделью `YandexGPT` и закеширует артефакты в `artifacts/`.

### Требования к данным

- `dataset/result.json` — JSON‑экспорт истории чата. Поддерживаются распространённые форматы:
  - Словарь с полем `messages` (список сообщений).
  - Верхний уровень — список сообщений.
  - Сообщения содержат `text` (строка или список частей текста), `date`, опционально `from`/`sender`.

### Обзор конвейера

1. Предобработка и нормализация сообщений (дедупликация, очистка текста, приведение дат).
2. Эмбеддинги моделью Yandex Cloud Embeddings (кэш в SQLite в `artifacts/`).
3. Тематическое моделирование: PCA → KMeans; число кластеров автоматически подбирается по размеру корпуса; TF‑IDF термы по кластерам.
4. LLM‑разметка названий тем: `YandexGPT` формирует короткие человеко‑читаемые заголовки.
5. Интерактивное открытие интентов и zero‑shot классификация (косинусная близость эмбеддингов, опционально с LLM‑подсказками).
6. Глубокий отчёт (deep research) по выбранным подмножествам данных и темам.

### Структура проекта

```
app/
  config.py
  data_loader.py
  embeddings.py
  topics.py
  intents.py
  report.py
  storage.py
streamlit_app.py
artifacts/           # генерируемые артефакты
reports/             # отчёты
dataset/             # входные данные (уже присутствуют)
```

### Переменные окружения

- `FOLDER_ID` — каталог в Яндекс Облаке, где опубликованы модели YandexGPT/Yandex Embeddings.
- `SERVICE_ACCOUNT_ID` — идентификатор сервисного аккаунта с доступом к моделям.
- `KEY_ID` — идентификатор ключа сервисного аккаунта.
- `PRIVATE_KEY` — путь к приватному ключу (PEM), используемому для подписи JWT.
- `API_KEY_EMBEDDER` — API-ключ для Yandex Cloud Embeddings.

### Архитектура и концепции

Система построена послойно, между этапами сохраняются артефакты:

- **Загрузка данных (app/data_loader.py)**: Преобразует `dataset/result.json` в нормализованный DataFrame с полями `message_id`, `sender`, `date`, `text`. Неформатный контент (медиа) игнорируется.
- **Векторизация (эмбеддинги или TF‑IDF)**:
  - Эмбеддинги моделью `text-embedding-3-small` с файловым кэшем в SQLite (`artifacts/embeddings_cache.sqlite`).
  - TF‑IDF доступен как фоллбек (настраивается в UI) — полезно без ключа или для быстрых локальных проверок.
- **Снижение размерности и кластеризация (app/topics.py)**:
  - PCA проецирует в пространство `pNNN`; KMeans объединяет сообщения в кластеры. Число кластеров подбирается по размеру корпуса в пределах заданных границ.
  - TF‑IDF термы на кластер; краткие названия тем генерируются `gpt-4.1` (фоллбек: топ‑термы).
- **Интенты и zero‑shot фильтрация (app/intents.py)**:
  - Начальный набор интентов предлагается LLM по меткам кластеров; пользователь редактирует список.
  - Интенты и сообщения кодируются эмбеддингами; далее считается косинусная близость и выбираются релевантные сообщения.
  - Поле «первичный запрос» позволяет ранжировать интенты по релевантности к цели исследования.
- **Синтез отчёта (app/report.py)**:
  - Генерация аналитического отчёта по выборке сообщений с цитированием фрагментов.
  - Регенерация с дополнительными комментариями/инструкциями.
  - Чат по отчёту: ответы опираются только на содержание отчёта.
- **Хранилище (app/storage.py)**: Артефакты сохраняются в `artifacts/` и `reports/` (Parquet, JSON, SQLite, Markdown), ускоряя повторные запуски и позволяя итеративное исследование.

### Сценарии работы в UI

1. Загрузка и кластеризация
   - В сайдбаре выберите векторизатор: Embeddings или TF‑IDF.
   - При необходимости перезапустите построение тем (измените PCA/число кластеров).
   - Просмотрите карту тем и таблицу меток кластеров.
   - Откройте «Topic activity timeline»: выберите несколько тем и гранулярность (Day/Week/Month) для просмотра динамики активности во времени.

2. Интенты и zero‑shot
   - Проверьте и отредактируйте предложенные интенты.
   - (Опционально) Укажите первичный исследовательский запрос — система порекомендует релевантные интенты.
   - Выберите несколько интентов и запустите zero‑shot фильтрацию; в результатах указаны оценки на сообщение.

3. Объединённый отчёт
   - Отметьте интенты, которые хотите включить, и задайте Top N на интент.
   - Сгенерируйте объединённый отчёт; он сохранится в `reports/` и отобразится в приложении.
   - Вкладки просмотра: Preview (рендер Markdown), Raw (исходный Markdown), Download (скачивание `.md`).

4. Регенерация и чат
   - Добавьте комментарии/инструкции и перегенерируйте отчёт.
   - Полноценный чат‑интерфейс: окно диалога (messages) и поле ввода; есть кнопка сброса контекста.
   - Контекст чата автоматически сбрасывается при генерации нового отчёта; ответы опираются только на содержимое отчёта.

### Анализ активности по темам (таймлайн)

- Раздел «Topic activity timeline» позволяет оценить, как менялась активность обсуждений по выбранным темам на протяжении времени.
- Выберите один или несколько кластеров (тем) — названия подтягиваются из LLM‑разметки.
- Настройте гранулярность агрегации: Day / Week / Month. Внутри используется `pandas.resample` по полю даты.
- На графике отображается количество сообщений в каждый период для каждой выбранной темы (Plotly line chart).
- Если в датасете отсутствуют валидные метки времени — интерфейс сообщит об этом.

### Детали реализации

- Кэш эмбеддингов: SQLite‑таблица по ключу `(message_id, model)`, хранит сериализованные `float32`‑вектора.
- Разметка тем: сжатая подсказка (prompt) просит заголовки длиной 3–6 слов для каждого кластера.
- Zero‑shot фильтрация: косинусная близость между эмбеддингами интентов и сообщений; параметры `top_k` и `min_score` настраиваются (в UI и в `scripts/check_zero_shot.py`).
- Фоллбеки: при отсутствии cred'ов Яндекс GPT — TF‑IDF признаки и эвристические метки тем; zero‑shot требует эмбеддингов и ключа.
- Streamlit: двумерные/трёхмерные проекции (Plotly), таблицы для меток и совпадений, вкладки для просмотра отчёта.

### Артефакты хранения

- `artifacts/embeddings.parquet` — эмбеддинги сообщений (`eNNNN`‑колонки).
- `artifacts/tfidf.parquet` — TF‑IDF признаки (если выбран соответствующий режим).
- `artifacts/projections.parquet` — PCA проекции `pNNN`.
- `artifacts/clusters.parquet` — соответствие `message_id` → `cluster`.
- `artifacts/cluster_labels.json` — метки кластеров.
- `artifacts/embeddings_cache.sqlite` — кэш эмбеддингов.
- `reports/report_YYYYMMDD_HHMMSS.md` — сгенерированные отчёты.

### Устранение неполадок

- «IAM token request failed» или «Missing Yandex GPT credentials»: проверьте переменные `FOLDER_ID`, `SERVICE_ACCOUNT_ID`, `KEY_ID`, `PRIVATE_KEY`.
- «streamlit not found»: запускайте через `.venv\Scripts\python -m streamlit run streamlit_app.py`.
- Пустой датасет: проверьте наличие `dataset/result.json` и соответствие поддерживаемому формату.
- Медленный первый запуск: эмбеддинги и кластеры кэшируются; повторные запуски быстрее.

### Инструменты разработчика

- Быстрая проверка zero‑shot фильтрации:

```powershell
.venv\Scripts\python -m scripts.check_zero_shot
```

При необходимости подстройте `top_k` / `min_score` в скрипте.

### Продуктовый подход и принципы

Этот раздел описывает, что именно решает система на уровне продукта, почему выбраны такие подходы и как с ними эффективно работать.

#### Для кого и зачем

- **Продакт‑менеджеры и аналитики**: быстрое выявление трендов и болей пользователей из больших массивов переписок без ручной вёрстки классификаторов.
- **Лиды команд и исследователи**: ускорение гипотезогенерации и подготовка аргументированных отчётов с цитатами.
- **Службы поддержки/CS**: оперативное выделение сегментов сообщений по интентам (жалобы, запросы фич, баг‑репорты) для последующих действий.

Ключевая ценность — сокращение времени от «сырая история чатов» до «структурированных инсайтов с приоритетами и рекомендациями».

#### Ментальная модель работы

1) **Картирование пространства** (кластеризация тем)
- Мы строим эмбеддинги сообщений, проектируем в низкоразмерное пространство и группируем близкое по смыслу. Получаем «карту тем» и короткие названия кластеров.
- Результат: наглядная карта обсуждений, на которую можно опираться дальше.

2) **Формулировка целей и интентов** (zero‑shot извлечение)
- Пользователь формулирует цель (primary query) и редактирует список интентов. Система подсказывает, какие интенты релевантны цели.
- Zero‑shot фильтрация собирает релевантные сообщения по каждому интенту, ранжируя их по сходству.

3) **Синтез и коммуникация** (отчёт и чат)
- Из выбранных сообщений формируется отчёт: краткое резюме, факты/цитаты, риски и рекомендации.
- Регенерация с комментариями позволяет уточнять выводы. Чат по отчёту помогает отвечать на уточняющие вопросы, не выходя за рамки контента отчёта.

#### Почему такой технологический стек

- **Unsupervised + LLM разметка**: не требует заранее размеченных данных, хорошо масштабируется на новые домены.
- **Zero‑shot**: позволяет выделять релевантные сообщения к любым формулировкам интентов без обучения модели.
- **Кэширование артефактов**: экономит бюджет и время; повторные запуски быстры.
- **TF‑IDF фоллбек**: система остаётся полезной без ключа к LLM.

#### Контроль качества результатов

- **Прозрачность**: карта тем, термы кластеров, баллы `intent_score`, цитаты в отчётах.
- **Интерактивность**: можно править интенты, пороги, объединять несколько интентов, уточнять отчёт комментариями.
- **Воспроизводимость**: артефакты сохраняются (эмбеддинги, кластеры, метки, отчёты).

Практические советы:
- Для точности делайте интенты конкретными («Ошибки оплаты при Apple Pay в iOS» лучше, чем «Ошибки оплаты»).
- Используйте поле первичного запроса — подсказки помогут выбрать релевантные интенты.
- Регулируйте Top N и пороги, чтобы балансировать полноту/точность.

#### Производительность и стоимость

- Эмбеддинги кэшируются в SQLite; пересчитываются только новые сообщения.
- Обработка идёт батчами, а артефакты (Parquet/JSON) позволяют возобновлять шаги без повторов.
- При необходимости поменяйте модель генерации, обновив параметр `chat_model` в `app/config.py` (например, `yandexgpt-lite`, `yandexgpt-pro`).

#### Приватность и безопасность

- Данные и артефакты хранятся локально в папках проекта.
- Передача к внешним сервисам ограничивается шагами, где вы используете LLM; при отсутствии ключа используются локальные эвристики.

#### Ограничения подхода

- Малые датасеты дают мало устойчивые кластеры — увеличивайте объём или уточняйте интенты.
- Очень «шумные»/мультиязычные чаты требуют дополнительных фильтров предобработки.
- LLM‑ответы ограничены контентом отчёта, чтобы снижать риск «галлюцинаций».

#### Дорожная карта (возможные расширения)

- Сравнение периодов («до/после релиза», «Q1 vs Q2»), автоматический change‑detection.
- Active learning: быстрое дообучение на пользовательских пометках.
- Расширенный экспорт (PDF/HTML), интеграции (Confluence/Slack/Jira).
- Семантические фильтры по атрибутам (автор, канал, timezone) и по времени.
- Многомодельная поддержка эмбеддингов и чат‑моделей, настройка температуры и инструкций.

#### Типовые сценарии

- Приоритезация запросов пользователей: сбор фактуры для roadmap.
- Анализ баг‑репортов из чатов поддержки: фиксация регрессий и критичности.
- Исследование восприятия релизов: «что улучшили/что сломалось/чего ждут».
- Подготовка обзоров рынка/конкурентов на базе внешних чатов/форумов.
<<<<<<< Updated upstream


=======
## REST API server

A FastAPI service (`api_server.py`) exposes datasets, metrics, and topic-map data for the new React dashboard.

### Launch
```bash
python -m uvicorn api_server:app --reload --port 8000
```

Configure the frontend with `VITE_API_BASE_URL` if the API runs on a different host or port. The default is `http://localhost:8000/api`.
>>>>>>> Stashed changes
## Telegram Synchronization

- Configure `TELEGRAM_API_ID`, `TELEGRAM_API_HASH`, and either `TELEGRAM_SESSION_STRING` or `TELEGRAM_SESSION_PATH` in `.env`. The provided app id/hash match the project Telegram application.
- Generate a reusable session string with Telethon (`python -m telethon.sessions`). Place it in `TELEGRAM_SESSION_STRING` to avoid interactive login inside the API server.
- The `POST /api/datasets/telegram-sync` endpoint downloads up to 3000 recent posts across `tb_invest_official`, `SberInvestments`, `alfa_investments`, and `centralbank_russia` within the requested date range and runs clustering immediately.
- Frontend landing form now triggers this endpoint; if the selected end date is in the future it automatically clamps to the current moment. When fewer clusters are discovered than requested, all available clusters are returned.
# FinamHack-public
